{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z73OosQ2duOy",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zrV3WBfd3ET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "9a8594e9-93b6-4c93-b9eb-50071a3ddb79"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old()."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-05-24 10:51:50--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-05-24 10:51:50 (57.7 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "V-i5RB4XduO5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c5ab7e98-161c-4486-f69b-d006b1e88c86"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhSXahsHduPF",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "3WOvzpRWduPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]\n",
        "    names = [name + pad_token for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "K0xEJAJ5duPS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "31954b60-ec45-461a-93e3-b5537b5e92cf"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael#\n",
            " Claresta#\n",
            " Glory#\n",
            " Liliane#\n",
            " Prissie#\n",
            " Geeta#\n",
            " Giovanne#\n",
            " Piggy#\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "V14j4oYWduPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "723999cc-47ab-4843-d8b6-c2398e339400"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAGoRJREFUeJzt3X2UXXV97/H3h/BQQB6CGQMkgUEM\nKLA04BSwCuKlQHi4BL23GOqFoGigBatX1vUCvS1UpCu1UipLDA2QBioEKQ8lFRAiVSmtQSYYQ8KD\nDBDIhEkyGB4suKKB7/1j/0Y3wzkz52nmZPL7vNY6a/b5/n77t7/nTHK+Z//23rMVEZiZWZ62ancC\nZmbWPi4CZmYZcxEwM8uYi4CZWcZcBMzMMuYiYGaWMRcB26JJCknvacN2j5LU28T6l0j6dlreS9J/\nSRrXotyulvQXrcizwthHSHqyVePZyHMRyICkj0j6T0mvSNog6T8k/X6789qSjGSxiYjnI+IdEfHG\nMDmcKenBGsY7JyIubUVug193RPx7ROzfirFtdGzd7gRsZEnaGfgu8CfALcC2wBHAxnbmZe0hadxw\nxcTy4j2BLd9+ABGxMCLeiIhfRcR9EbF8oIOkz0h6XNJLku6VtHep7RhJT6S9iG9K+pGkz6a2305Z\npOed6Zvh1un5LpKuk9QnaY2krw5MaQx8a5X09bTdZyUdXxprN0n/KOmF1P4vpbaTJC2T9HLaw3l/\nLW+EpO3S9p6XtC5Ni2yf2o6S1CvpfEnrU86fLq37Tkn/KulVSQ+n1/JgansgdftZmrb5ZGm9iuNV\nyG2f9N7+UtJiYMIQ7+uZkp5JfZ+V9ClJ7wOuBj6Ucng59V0gaa6kuyW9Bnwsxb46aPsXSXpR0ipJ\nnyrFfzjw+y7/3qq97sHTS5Lel8Z4WdJKSSeX2hZIukrSXem1PCRp3+F+j9ZaLgJbvp8Db0i6XtLx\nksaXGyXNAC4CPgF0AP8OLExtE4Dbgf9H8aH0NPDhOra9ANgEvAc4GDgW+Gyp/TDgyTT214DrJCm1\n/ROwA3Ag8C7gipTTwcB84GzgncA/AIskbVdDPnMoiuK0lNMk4C9L7bsDu6T4WcBVpffrKuC11GdW\negAQEUemxQ+kaZvv1DDeYDcBS9N7cWl5/DJJOwJXAsdHxE7AHwDLIuJx4BzgxymHXUur/TFwGbAT\nUGm6aPe03Ulpu/MkDTulM8TrHsh1G+BfgfsofoefB24cNPZM4K+A8UBPytNGU0T4sYU/gPdRfCD3\nUnwoLwImprZ7gLNKfbcCXgf2Bs4AlpTalMb4bHp+CfDtUnsnEBTTjBMpppy2L7WfBvwgLZ8J9JTa\ndkjr7g7sAbwJjK/wWuYClw6KPQl8tMprD4oPfFF8iO9bavsQ8GxaPgr4FbB1qX09cDgwDvgNsH+p\n7avAg4O3U3pedbwKOe6Vfi87lmI3Dby3g97XHYGXgf9Rfm9L7+mDg2ILgBsqxL5aynPwtm8B/iIt\n/3Dg911pG1Ved29aPgJYC2xVal8IXFLK49pS2wnAE+3+/5Lbw3sCGYiIxyPizIiYDBwE7An8fWre\nG/hG2l1/GdhA8YE5KfVbXRonys+HsTewDdBXGvsfKL4RDlhbGvv1tPgOYAqwISJeqjLu+QNjpnGn\npFyH0kFRaJaW1vteig/4RURsKj1/PeXTQfEBXH7ttbwP1cYbbE/gpYh4rRR7rtKAqc8nKb7196Wp\nlPcOk8dwuVba9nDvZy32BFZHxJuDxp5Uer62tFzt/bER5CKQmYh4guIb2EEptBo4OyJ2LT22j4j/\nBPooPmABSFM1U0rDvUbxwTpg99Lyaoo9gQmlcXeOiANrSHM1sJukXau0XTYo3x0iYuEwY75I8c38\nwNJ6u0RELR86/RTflieXYlOq9G1EHzA+TfUM2Kta54i4NyKOodhjegK4ZqCp2irDbL/Stl9Iy0P9\njofzAjBFUvlzZi9gTR1j2AhzEdjCSXpvOjg5OT2fQjEtsyR1uRq4UNKBqX0XSX+U2u4CDpT0iXRQ\n8s9464fAMuBIFeex7wJcONAQEX0Uc8GXS9pZ0laS9pX00eFyTuveA3xL0nhJ20gamH++BjhH0mEq\n7CjpREk7DTPmm2ndKyS9K73WSZKOqyGfNyiOjVwiaYf0zfuMQd3WAe8ebqwq4z8HdAN/JWlbSR8B\n/nulvpImSpqRPrQ3Av9FMXU2kMNkSds2kMbAto8ATgL+OcWXAZ9Ir/s9FMc2yoZ63Q9RfLv/cvod\nHpVe180N5GcjxEVgy/dLigOwD6WzQ5YAK4DzASLiDuBvgJslvZrajk9tLwJ/RHFA9RfAVOA/BgaO\niMXAd4DlFAc1vzto22dQnJL6GPAScCvFt9danE4xD/8ExVz6F9M2u4HPAd9MY/ZQzFPX4v+m/kvS\na/0+UOs57edRHORdS3HQeiFvPc32EuD6NNV0ao1jlv0xxe9pA3AxcEOVflsBX6L4lr0B+CjF6b8A\n/wasBNZKerGOba+leC9fAG4Ezkl7jFAckP81xYf99am97BKqvO6I+DXFh/7xFHti3wLOKI1tmwEV\n07xmtZH0Q4oDlte2O5d2kvQ3wO4RUfEsHrOxwnsCZjVI02rvT1NQh1JMi9zR7rzMmuUrhs1qsxPF\nFNCeFFMjlwN3tjUjsxbwdJCZWcY8HWRmlrHNfjpowoQJ0dnZ2e40zMzGjKVLl74YER3D9xwDRaCz\ns5Pu7u52p2FmNmZIqnjFeSWeDjIzy5iLgJlZxlwEzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4C\nZmYZcxEwM8vYZn/FsG1eOi+4q67+q+acOEKZmFkreE/AzCxjwxYBSVMk/UDSY5JWSvpCiu8mabGk\np9LP8SkuSVdK6pG0XNIhpbFmpf5PSfIdmczM2qyWPYFNwPkRcQBwOHCupAOAC4D7I2IqcH96DsX9\nRKemx2xgLhRFg+LeqYcBhwIXDxQOMzNrj2GLQET0RcQjafmXwOPAJGAGxY2nST9PScszgBuisATY\nVdIewHHA4ojYEBEvAYuB6S19NWZmVpe6jglI6gQOBh4CJkZEX2paC0xMy5OA1aXVelOsWrzSdmZL\n6pbU3d/fX0+KZmZWh5qLgKR3ALcBX4yIV8ttUdyjsmX3qYyIeRHRFRFdHR013RfBzMwaUFMRkLQN\nRQG4MSJuT+F1aZqH9HN9iq8BppRWn5xi1eJmZtYmtZwdJOA64PGI+LtS0yJg4AyfWcCdpfgZ6Syh\nw4FX0rTRvcCxksanA8LHppiZmbVJLReLfRg4HXhU0rIUuwiYA9wi6SzgOeDU1HY3cALQA7wOfBog\nIjZIuhR4OPX7SkRsaMmrMDOzhgxbBCLiQUBVmo+u0D+Ac6uMNR+YX0+CZmY2cnzFsJlZxlwEzMwy\n5iJgZpYxFwEzs4y5CJiZZcxFwMwsY76pzBbGN30xs3p4T8DMLGMuAmZmGXMRMDPLmIuAmVnGXATM\nzDLmImBmljEXATOzjLkImJllzEXAzCxjtdxecr6k9ZJWlGLfkbQsPVYN3HFMUqekX5Xari6t80FJ\nj0rqkXRlum2lmZm1US1/NmIB8E3ghoFARHxyYFnS5cArpf5PR8S0CuPMBT4HPERxC8rpwD31p2xm\nZq0y7J5ARDwAVLwXcPo2fyqwcKgxJO0B7BwRS9LtJ28ATqk/XTMza6VmjwkcAayLiKdKsX0k/VTS\njyQdkWKTgN5Sn94Uq0jSbEndkrr7+/ubTNHMzKpptgicxlv3AvqAvSLiYOBLwE2Sdq530IiYFxFd\nEdHV0dHRZIpmZlZNw39KWtLWwCeADw7EImIjsDEtL5X0NLAfsAaYXFp9coqZmVkbNbMn8IfAExHx\n22keSR2SxqXldwNTgWciog94VdLh6TjCGcCdTWzbzMxaoJZTRBcCPwb2l9Qr6azUNJO3HxA+Elie\nThm9FTgnIgYOKv8pcC3QAzyNzwwyM2u7YaeDIuK0KvEzK8RuA26r0r8bOKjO/MzMbAT5imEzs4y5\nCJiZZcxFwMwsYy4CZmYZcxEwM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZm\nGXMRMDPLmIuAmVnGXATMzDLmImBmlrFa7iw2X9J6SStKsUskrZG0LD1OKLVdKKlH0pOSjivFp6dY\nj6QLWv9SzMysXrXsCSwApleIXxER09LjbgBJB1DcdvLAtM63JI1L9x2+CjgeOAA4LfU1M7M2quX2\nkg9I6qxxvBnAzRGxEXhWUg9waGrriYhnACTdnPo+VnfGZmbWMs0cEzhP0vI0XTQ+xSYBq0t9elOs\nWrwiSbMldUvq7u/vbyJFMzMbSqNFYC6wLzAN6AMub1lGQETMi4iuiOjq6Oho5dBmZlYy7HRQJRGx\nbmBZ0jXAd9PTNcCUUtfJKcYQcTMza5OG9gQk7VF6+nFg4MyhRcBMSdtJ2geYCvwEeBiYKmkfSdtS\nHDxe1HjaZmbWCsPuCUhaCBwFTJDUC1wMHCVpGhDAKuBsgIhYKekWigO+m4BzI+KNNM55wL3AOGB+\nRKxs+asxM7O61HJ20GkVwtcN0f8y4LIK8buBu+vKzszMRlRDxwTMRkrnBXfVvc6qOSeOQCZmefCf\njTAzy5iLgJlZxlwEzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZcxEwM8uYi4CZWcZcBMzM\nMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGPDFgFJ8yWtl7SiFPtbSU9IWi7pDkm7pninpF9JWpYeV5fW\n+aCkRyX1SLpSkkbmJZmZWa1q2RNYAEwfFFsMHBQR7wd+DlxYans6Iqalxzml+FzgcxT3HZ5aYUwz\nMxtlwxaBiHgA2DAodl9EbEpPlwCThxoj3Zh+54hYEhEB3ACc0ljKZmbWKq04JvAZ4J7S830k/VTS\njyQdkWKTgN5Sn94Uq0jSbEndkrr7+/tbkKKZmVXSVBGQ9OfAJuDGFOoD9oqIg4EvATdJ2rnecSNi\nXkR0RURXR0dHMymamdkQGr7RvKQzgZOAo9MUDxGxEdiYlpdKehrYD1jDW6eMJqeYmZm1UUN7ApKm\nA18GTo6I10vxDknj0vK7KQ4APxMRfcCrkg5PZwWdAdzZdPZmZtaUYfcEJC0EjgImSOoFLqY4G2g7\nYHE603NJOhPoSOArkn4DvAmcExEDB5X/lOJMo+0pjiGUjyOYmVkbDFsEIuK0CuHrqvS9DbitSls3\ncFBd2ZmZ2YjyFcNmZhlzETAzy5iLgJlZxlwEzMwy5iJgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZ\ncxEwM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGaupCEiaL2m9pBWl2G6S\nFkt6Kv0cn+KSdKWkHknLJR1SWmdW6v+UpFmtfzlmZlaPWvcEFgDTB8UuAO6PiKnA/ek5wPEUN5if\nCswG5kJRNCjuT3wYcChw8UDhMDOz9qipCETEA8CGQeEZwPVp+XrglFL8higsAXaVtAdwHLA4IjZE\nxEvAYt5eWMzMbBQ1c0xgYkT0peW1wMS0PAlYXerXm2LV4m8jabakbknd/f39TaRoZmZDacmB4YgI\nIFoxVhpvXkR0RURXR0dHq4Y1M7NBmikC69I0D+nn+hRfA0wp9ZucYtXiZmbWJs0UgUXAwBk+s4A7\nS/Ez0llChwOvpGmje4FjJY1PB4SPTTEzM2uTrWvpJGkhcBQwQVIvxVk+c4BbJJ0FPAecmrrfDZwA\n9ACvA58GiIgNki4FHk79vhIRgw82m5nZKKqpCETEaVWajq7QN4Bzq4wzH5hfc3ZmZjaifMWwmVnG\natoTsNbovOCuuvqvmnPiCGViZlbwnoCZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZm\nGfN1ApYdX69h9jveEzAzy5iLgJlZxlwEzMwy5iJgZpYxFwEzs4y5CJiZZazhIiBpf0nLSo9XJX1R\n0iWS1pTiJ5TWuVBSj6QnJR3XmpdgZmaNavg6gYh4EpgGIGkcxU3j76C4neQVEfH1cn9JBwAzgQOB\nPYHvS9ovIt5oNAczM2tOq6aDjgaejojnhugzA7g5IjZGxLMU9yA+tEXbNzOzBrSqCMwEFpaenydp\nuaT5ksan2CRgdalPb4q9jaTZkroldff397coRTMzG6zpIiBpW+Bk4J9TaC6wL8VUUR9web1jRsS8\niOiKiK6Ojo5mUzQzsypasSdwPPBIRKwDiIh1EfFGRLwJXMPvpnzWAFNK601OMTMza5NWFIHTKE0F\nSdqj1PZxYEVaXgTMlLSdpH2AqcBPWrB9MzNrUFN/RVTSjsAxwNml8NckTQMCWDXQFhErJd0CPAZs\nAs71mUFmZu3VVBGIiNeAdw6KnT5E/8uAy5rZppmZtY6vGDYzy5iLgJlZxlwEzMwy5iJgZpYxFwEz\ns4y5CJiZZcxFwMwsYy4CZmYZcxEwM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMu\nAmZmGWvFjeZXSXpU0jJJ3Sm2m6TFkp5KP8enuCRdKalH0nJJhzS7fTMza1yr9gQ+FhHTIqIrPb8A\nuD8ipgL3p+dQ3JR+anrMBua2aPtmZtaAkZoOmgFcn5avB04pxW+IwhJg10E3pjczs1HUiiIQwH2S\nlkqanWITI6IvLa8FJqblScDq0rq9KfYWkmZL6pbU3d/f34IUzcyskqZuNJ98JCLWSHoXsFjSE+XG\niAhJUc+AETEPmAfQ1dVV17pmZla7pvcEImJN+rkeuAM4FFg3MM2Tfq5P3dcAU0qrT04xMzNrg6aK\ngKQdJe00sAwcC6wAFgGzUrdZwJ1peRFwRjpL6HDgldK0kZmZjbJmp4MmAndIGhjrpoj4nqSHgVsk\nnQU8B5ya+t8NnAD0AK8Dn25y+2Zm1oSmikBEPAN8oEL8F8DRFeIBnNvMNs3MrHV8xbCZWcZcBMzM\nMuYiYGaWMRcBM7OMuQiYmWXMRcDMLGMuAmZmGXMRMDPLmIuAmVnGWvFXRM2spPOCu+rqv2rOiSOU\nidnwvCdgZpYxFwEzs4y5CJiZZcxFwMwsYy4CZmYZcxEwM8tYw0VA0hRJP5D0mKSVkr6Q4pdIWiNp\nWXqcUFrnQkk9kp6UdFwrXoCZmTWumesENgHnR8Qj6T7DSyUtTm1XRMTXy50lHQDMBA4E9gS+L2m/\niHijiRxayud3m1luGt4TiIi+iHgkLf8SeByYNMQqM4CbI2JjRDxLcZ/hQxvdvpmZNa8lxwQkdQIH\nAw+l0HmSlkuaL2l8ik0CVpdW62XoomFmZiOs6SIg6R3AbcAXI+JVYC6wLzAN6AMub2DM2ZK6JXX3\n9/c3m6KZmVXRVBGQtA1FAbgxIm4HiIh1EfFGRLwJXMPvpnzWAFNKq09OsbeJiHkR0RURXR0dHc2k\naGZmQ2jm7CAB1wGPR8TfleJ7lLp9HFiRlhcBMyVtJ2kfYCrwk0a3b2ZmzWvm7KAPA6cDj0palmIX\nAadJmgYEsAo4GyAiVkq6BXiM4syiczenM4PMzHLUcBGIiAcBVWi6e4h1LgMua3SbZmbWWr5i2Mws\nYy4CZmYZcxEwM8uYi4CZWcZcBMzMMuYiYGaWMRcBM7OMuQiYmWWsmSuGzawN6r3vBfjeF1ad9wTM\nzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhlzETAzy5iLgJlZxkb9YjFJ04FvAOOAayNizmjn\nYGZDq/eCNF+MNnaNahGQNA64CjgG6AUelrQoIh4bie01cmWlmVlORntP4FCgJyKeAZB0MzCD4ubz\nZpaJkd7T8J/WqJ0iYvQ2Jv1PYHpEfDY9Px04LCLOG9RvNjA7Pd0feLLBTU4AXmxw3XYbq7mP1bzB\nubeLc2+9vSOio5aOm+UfkIuIecC8ZseR1B0RXS1IadSN1dzHat7g3NvFubfXaJ8dtAaYUno+OcXM\nzKwNRrsIPAxMlbSPpG2BmcCiUc7BzMySUZ0OiohNks4D7qU4RXR+RKwcwU02PaXURmM197GaNzj3\ndnHubTSqB4bNzGzz4iuGzcwy5iJgZpaxLbYISBon6aeSvtvuXOohaVdJt0p6QtLjkj7U7pxqJel/\nS1opaYWkhZJ+r905VSNpvqT1klaUYrtJWizpqfRzfDtzrKZK7n+b/s0sl3SHpF3bmWM1lXIvtZ0v\nKSRNaEduQ6mWt6TPp/d9paSvtSu/ZmyxRQD4AvB4u5NowDeA70XEe4EPMEZeg6RJwJ8BXRFxEMWB\n/5ntzWpIC4Dpg2IXAPdHxFTg/vR8c7SAt+e+GDgoIt4P/By4cLSTqtEC3p47kqYAxwLPj3ZCNVrA\noLwlfYziLx58ICIOBL7ehryatkUWAUmTgROBa9udSz0k7QIcCVwHEBG/joiX25tVXbYGtpe0NbAD\n8EKb86kqIh4ANgwKzwCuT8vXA6eMalI1qpR7RNwXEZvS0yUU1+Bsdqq87wBXAF8GNsszVark/SfA\nnIjYmPqsH/XEWmCLLALA31P8g3qz3YnUaR+gH/jHNJV1raQd251ULSJiDcU3oeeBPuCViLivvVnV\nbWJE9KXltcDEdibThM8A97Q7iVpJmgGsiYiftTuXOu0HHCHpIUk/kvT77U6oEVtcEZB0ErA+Ipa2\nO5cGbA0cAsyNiIOB19h8pyTeIs2fz6AoZHsCO0r6X+3NqnFRnDu9WX4rHYqkPwc2ATe2O5daSNoB\nuAj4y3bn0oCtgd2Aw4H/A9wiSe1NqX5bXBEAPgycLGkVcDPw3yR9u70p1awX6I2Ih9LzWymKwljw\nh8CzEdEfEb8Bbgf+oM051WudpD0A0s8xtXsv6UzgJOBTMXYuANqX4ovDz9L/2cnAI5J2b2tWtekF\nbo/CTyhmHja7g9rD2eKKQERcGBGTI6KT4sDkv0XEmPhGGhFrgdWS9k+hoxk7f2b7eeBwSTukb0NH\nM0YOapcsAmal5VnAnW3MpS7pZk1fBk6OiNfbnU+tIuLRiHhXRHSm/7O9wCHp/8Lm7l+AjwFI2g/Y\nls3zL4oOaYsrAluAzwM3SloOTAP+us351CTtvdwKPAI8SvFva7O9pF7SQuDHwP6SeiWdBcwBjpH0\nFMWezWZ517squX8T2AlYLGmZpKvbmmQVVXLf7FXJez7w7nTa6M3ArDG0B/Zb/rMRZmYZ856AmVnG\nXATMzDLmImBmljEXATOzjLkImJllzEXAzCxjLgJmZhn7/waFKEQYqzhqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dssTY8sxduPi",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "9l4YiD0BduPl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7c73aad-1309-4eef-94b0-f1fcfbfb7eac"
      },
      "source": [
        "tokens = list(set(''.join(names)))\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcMeNS1RduPr",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "jEylPwL5duPu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = dict(zip(tokens, np.arange(len(tokens))))### YOUR CODE HERE: create a dictionary of {symbol -> its index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "VGlyhTj0duP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "hcuUp4VrduQG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "a88925d0-d1c7-428a-e378-d9bd6d3983ec"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael#\n",
            " Glory#\n",
            " Prissie#\n",
            " Giovanne#\n",
            "[[ 6 18 21 17 13 17 30 23 10 10]\n",
            " [ 6 54 23 38  0 44 10 10 10 10]\n",
            " [ 6 11  0 43 12 12 43 30 10 10]\n",
            " [ 6 54 43 38  3 17 46 46 30 10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEzLJo33duQQ",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/marina123123/intro_to_dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "hIzH3DPmduQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9B9sVcTNykUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "ZusBISsGduQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation=keras.activations.tanh) ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation=keras.activations.softmax)### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1hsI72WduQw",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/marina123123/intro_to_dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "DTcevV72duQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t]) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYSaFSLoduQ5",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "fUeGpxERduQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBJbt_VCduRD",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "oqbPDiATduRG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uuobu6y8duRL",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "kbNEW2yUduRO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "e75ace80-c27b-44ed-c00e-ba759a778098"
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVQe6KVJduRS",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "u9NV1NxHduRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "b463b6f5-adf8-4af1-b9a4-9e684cfcfe6f"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nV0qpGPT/s3nNqmvP6poAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq6fuSLsduRc",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "HvgbHQ1GduRf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "ABw4GU07duRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    \n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs, _ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "HtesMDtLduRw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "2c5f3ded-f3bb-48d6-b6c6-800449a909c0"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Rolrik\n",
            " Andanue\n",
            " Arlis\n",
            " Ceree\n",
            " Iunire\n",
            " Jnenwyr\n",
            " Geran\n",
            " Janniza\n",
            " Jatile\n",
            " Ranonate\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "sS5LcpZjduR1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "48599c37-6895-4813-aa72-2caf07361b9c"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpiocn\n",
            " Trumpil\n",
            " Trumpir\n",
            " Trumpa\n",
            " Trumpa\n",
            " Trumpe\n",
            " Trumpe\n",
            " Trumpa\n",
            " Trumpere\n",
            " Trumpe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "va3Ol0P6duR_",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "uhCWsEipduSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"mvolosnikova@gmail.com\"### YOUR TOKEN HERE ###\"\n",
        "COURSERA_EMAIL = \"fOGtKBrknMJdTUCs\"### YOUR EMAIL HERE ###\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "WdwrCTBnduSP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "301fe641-229b-4c18-cb47-a623444667e0"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "You used an invalid email or your token may have expired. Please make sure you have entered all fields correctly. Try generating a new token if the issue still persists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPBH0Wi-duSV",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "2y9h-LoXduSY",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "aHs35-_3duSZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "a05df8f1-7517-4a2c-fd51-25a7cf693bc7"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-81-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-81-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzOpStoOduSc",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "hNF0t8BnduSi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "bba08b84-03b0-4427-fa94-1f8153aa1803"
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "zz6NZDf1duSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "c7c239b2-0180-4357-f401-d44e1754bc89"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-83-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJj1yBY58aX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}